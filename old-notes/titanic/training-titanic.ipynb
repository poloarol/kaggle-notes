{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(os.path.join(os.getcwd(), f\"dataset/{file}\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = read_csv(\"train_engineered.csv\")\n",
    "titanic_copy = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Embarked', 'title', 'Age_present', 'Embarked_present'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_copy[\"Embarked\"] = titanic_copy['Embarked'].replace(np.nan, \"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_copy['Is_child'] = np.select([titanic_copy['title'].str.lower() == 'master'], ['Y'], 'N')\n",
    "titanic_copy['Nb_Fmly_Mem'] = titanic_copy['SibSp'].fillna(0) + titanic_copy['Parch'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Boy Age -> 3.5. Median Men Age -> 30.0\n"
     ]
    }
   ],
   "source": [
    "young_men = titanic_copy.loc[titanic_copy['title'] == \"Master\"]\n",
    "adult_men = titanic_copy.loc[(titanic_copy['title'] != \"Master\") & (titanic_copy['Sex'] == \"male\")]\n",
    "\n",
    "\n",
    "print(f\"Median Boy Age -> {young_men['Age'].median()}. Median Men Age -> {adult_men['Age'].median()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median fare paid per class. 1st class -> 60.287499999999994, 2nd class -> 14.25, 3rd class -> 8.05\n"
     ]
    }
   ],
   "source": [
    "first_class = titanic_copy.loc[titanic_copy['Pclass'] == 1]\n",
    "second_class = titanic_copy.loc[titanic_copy['Pclass'] == 2]\n",
    "third_class = titanic_copy.loc[titanic_copy['Pclass'] == 3]\n",
    "\n",
    "print(f\"Median fare paid per class. 1st class -> {first_class['Fare'].median()}, 2nd class -> {second_class['Fare'].median()}, 3rd class -> {third_class['Fare'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "young_men['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_men['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy[\"Age\"] = np.where(titanic_copy[\"Sex\"] == \"female\", 28, titanic_copy[\"Age\"],) # replace all women\n",
    "titanic_copy['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy[\"Age\"] = np.where(titanic_copy[\"title\"] == \"Master\", young_men[\"Age\"].median(), titanic_copy[\"Age\"]) # replace all young boys (title == master)\n",
    "titanic_copy['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy[\"Age\"] = np.where(titanic_copy[\"Sex\"] == \"male\", adult_men[\"Age\"].median(), titanic_copy[\"Age\"]) # replace all men title != \"Master\"\n",
    "titanic_copy['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived            False\n",
       "Pclass              False\n",
       "Sex                 False\n",
       "Age                 False\n",
       "SibSp               False\n",
       "Parch               False\n",
       "Fare                False\n",
       "Embarked            False\n",
       "title               False\n",
       "Age_present         False\n",
       "Embarked_present    False\n",
       "Is_child            False\n",
       "Nb_Fmly_Mem         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(titanic_copy, test_size=0.2, random_state=seed, stratify=titanic_copy[[\"Survived\", \"Pclass\", \"Sex\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"Survived\"]\n",
    "del train[\"Survived\"]\n",
    "\n",
    "y_test = test[\"Survived\"]\n",
    "del test[\"Survived\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived            False\n",
       "Pclass              False\n",
       "Sex                 False\n",
       "Age                 False\n",
       "SibSp               False\n",
       "Parch               False\n",
       "Fare                False\n",
       "Embarked            False\n",
       "title               False\n",
       "Age_present         False\n",
       "Embarked_present    False\n",
       "Is_child            False\n",
       "Nb_Fmly_Mem         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, OrdinalEncoder, FunctionTransformer\n",
    "\n",
    "\n",
    "numeric_features = [\"Age\", \"Fare\"]\n",
    "ordinal_features = [\"Pclass\"]\n",
    "categorical_features = [\"Sex\", \"SibSp\", \"Parch\", \"Embarked\", \"title\", \"Embarked_present\", \"Is_child\", \"Age_present\"]\n",
    "\n",
    "numeric_transformer = Pipeline([(\"scaler\", RobustScaler())])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"error\")\n",
    "ordinal_transformer = OrdinalEncoder(handle_unknown=\"error\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"ord\", ordinal_transformer, ordinal_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  [&#x27;Age&#x27;, &#x27;Fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;,\n",
       "                                                   &#x27;Embarked&#x27;, &#x27;title&#x27;,\n",
       "                                                   &#x27;Embarked_present&#x27;,\n",
       "                                                   &#x27;Is_child&#x27;, &#x27;Age_present&#x27;]),\n",
       "                                                 (&#x27;ord&#x27;, OrdinalEncoder(),\n",
       "                                                  [&#x27;Pclass&#x27;])])),\n",
       "                (&#x27;sampling&#x27;, SMOTE()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  [&#x27;Age&#x27;, &#x27;Fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;,\n",
       "                                                   &#x27;Embarked&#x27;, &#x27;title&#x27;,\n",
       "                                                   &#x27;Embarked_present&#x27;,\n",
       "                                                   &#x27;Is_child&#x27;, &#x27;Age_present&#x27;]),\n",
       "                                                 (&#x27;ord&#x27;, OrdinalEncoder(),\n",
       "                                                  [&#x27;Pclass&#x27;])])),\n",
       "                (&#x27;sampling&#x27;, SMOTE()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, RobustScaler())]),\n",
       "                                 [&#x27;Age&#x27;, &#x27;Fare&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                 [&#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;, &#x27;title&#x27;,\n",
       "                                  &#x27;Embarked_present&#x27;, &#x27;Is_child&#x27;,\n",
       "                                  &#x27;Age_present&#x27;]),\n",
       "                                (&#x27;ord&#x27;, OrdinalEncoder(), [&#x27;Pclass&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;Fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;, &#x27;title&#x27;, &#x27;Embarked_present&#x27;, &#x27;Is_child&#x27;, &#x27;Age_present&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ord</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['Age', 'Fare']),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  ['Sex', 'SibSp', 'Parch',\n",
       "                                                   'Embarked', 'title',\n",
       "                                                   'Embarked_present',\n",
       "                                                   'Is_child', 'Age_present']),\n",
       "                                                 ('ord', OrdinalEncoder(),\n",
       "                                                  ['Pclass'])])),\n",
       "                ('sampling', SMOTE()),\n",
       "                ('classifier', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", LogisticRegression(random_state=seed))])\n",
    "logit.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "classifiers = {\n",
    "    \"logit\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", LogisticRegression(random_state=seed, n_jobs=-1))]),\n",
    "    \"rf\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", RandomForestClassifier(random_state=seed, n_jobs=-1))]),\n",
    "    \"lbgm\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", LGBMClassifier(random_state=seed, n_jobs=-1))]),\n",
    "    \"neural\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", MLPClassifier(random_state=seed))]),\n",
    "    \"ada\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", AdaBoostClassifier(random_state=seed))]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns    \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "reports = []\n",
    "kfold_results = []\n",
    "names = []\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    names.append(name)\n",
    "    \n",
    "    # kfold\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "    kfold_result = cross_val_score(classifier, train, y_train, cv=kfold, scoring='accuracy')\n",
    "    kfold_results.append(kfold_result)\n",
    "    \n",
    "    # train test split\n",
    "    classifier.fit(train, y_train)\n",
    "    predictions = classifier.predict(test)\n",
    "    reports.append({\n",
    "        'name': name,\n",
    "        'confusion': confusion_matrix(y_test, predictions),\n",
    "        'accuracy': accuracy_score(y_test, predictions),\n",
    "        'f1': f1_score(y_test, predictions)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "g = sns.boxplot(data=kfold_results)\n",
    "g.set_title('Model Evaluation\\n KFold 10 Splits')\n",
    "g.set_xlabel('Model')\n",
    "g.set_ylabel('Accuracy')\n",
    "g.set_xticklabels(names, rotation=90)\n",
    "g.get_figure().tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "logit\n",
      "--------------------\n",
      "F1 Score:         0.7368421052631577\n",
      "Accuracy:         0.8044692737430168\n",
      "Mean KFold (10):  0.7952073552425666\n",
      "Std. KFold (10):  0.04687906091614488\n",
      "TPR:              0.7205882352941176\n",
      "FPR:              0.14414414414414414\n",
      "Specificity:      0.8558558558558559\n",
      "Precision:        0.7538461538461538\n",
      "\n",
      "--------------------\n",
      "rf\n",
      "--------------------\n",
      "F1 Score:         0.7194244604316546\n",
      "Accuracy:         0.7821229050279329\n",
      "Mean KFold (10):  0.7952073552425666\n",
      "Std. KFold (10):  0.04687906091614488\n",
      "TPR:              0.7352941176470589\n",
      "FPR:              0.1891891891891892\n",
      "Specificity:      0.8108108108108107\n",
      "Precision:        0.704225352112676\n",
      "\n",
      "--------------------\n",
      "lbgm\n",
      "--------------------\n",
      "F1 Score:         0.7014925373134329\n",
      "Accuracy:         0.776536312849162\n",
      "Mean KFold (10):  0.7952073552425666\n",
      "Std. KFold (10):  0.04687906091614488\n",
      "TPR:              0.6911764705882353\n",
      "FPR:              0.17117117117117117\n",
      "Specificity:      0.8288288288288288\n",
      "Precision:        0.7121212121212122\n",
      "\n",
      "--------------------\n",
      "neural\n",
      "--------------------\n",
      "F1 Score:         0.696969696969697\n",
      "Accuracy:         0.776536312849162\n",
      "Mean KFold (10):  0.7952073552425666\n",
      "Std. KFold (10):  0.04687906091614488\n",
      "TPR:              0.6764705882352942\n",
      "FPR:              0.16216216216216217\n",
      "Specificity:      0.8378378378378378\n",
      "Precision:        0.71875\n",
      "\n",
      "--------------------\n",
      "ada\n",
      "--------------------\n",
      "F1 Score:         0.7222222222222222\n",
      "Accuracy:         0.776536312849162\n",
      "Mean KFold (10):  0.7952073552425666\n",
      "Std. KFold (10):  0.04687906091614488\n",
      "TPR:              0.7647058823529411\n",
      "FPR:              0.21621621621621623\n",
      "Specificity:      0.7837837837837838\n",
      "Precision:        0.6842105263157895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_model_stats(kfold_result, report):\n",
    "    tn = report['confusion'][0][0] # True negative\n",
    "    fp = report['confusion'][0][1] # False positive\n",
    "    fn = report['confusion'][1][0] # False negative\n",
    "    tp = report['confusion'][1][1] # True positive\n",
    "    \n",
    "    mr = 1 - report['accuracy'] # Misclassification rate\n",
    "    tpr = tp / (fn + tp) # True positive rate\n",
    "    fpr = fp / (tn + fp) # False positive rate\n",
    "    spec = 1 - fpr # Specificity\n",
    "    prec = tp / (fp + tp) # Precision    \n",
    "    \n",
    "    print('--------------------')\n",
    "    print(report['name'])\n",
    "    print('--------------------')\n",
    "    print('F1 Score:        ', report['f1'])\n",
    "    print('Accuracy:        ', report['accuracy'])\n",
    "    print('Mean KFold (10): ', kfold_result.mean())\n",
    "    print('Std. KFold (10): ', kfold_result.std())\n",
    "    print('TPR:             ', tpr)\n",
    "    print('FPR:             ', fpr)\n",
    "    print('Specificity:     ', spec)\n",
    "    print('Precision:       ', prec)\n",
    "    print()\n",
    "    \n",
    "for kfold, report in zip(kfold_results, reports):\n",
    "    print_model_stats(kfold_result, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.0.2)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: cliff in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (4.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (1.21.6)\n",
      "Requirement already satisfied: colorlog in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cliff->optuna) (4.12.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cliff->optuna) (4.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from colorlog->optuna) (0.4.5)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from importlib-metadata>=4.4->cliff->optuna) (3.8.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from stevedore>=2.0.1->cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def optimization_step(trial, name, train, y_train):\n",
    "    \n",
    "    pipe = None\n",
    "    \n",
    "    if name == \"rf\":\n",
    "        rf = {\n",
    "            'bootstrap': trial.suggest_categorical(\"bootstrap\", choices=[\"gini\", \"entropy\"]),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            'max_features': trial.suggest_float(\"max_features\", 0.01, 1.0),\n",
    "            'min_samples_leaf': trial.suggest_int(\"min_samples_leaf\", 3, 5),\n",
    "            'min_samples_split': trial.suggest_int(\"min_samples_split\", 3, 5),\n",
    "            'n_estimators': trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", choices=[\"gini\", \"entropy\"])\n",
    "        }\n",
    "        \n",
    "        pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", RandomForestClassifier(**rf, random_state=seed, n_jobs=-1))])\n",
    "        \n",
    "    if name == \"lgbm\":\n",
    "        lgbm = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 120, step=20),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        }\n",
    "        \n",
    "        pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", LGBMClassifier(**lgbm, random_state=seed, n_jobs=-1))])\n",
    "    \n",
    "    if name == \"neural\":\n",
    "        \n",
    "        n_layers = trial.suggest_int('hidden_layer_sizes', 1, 4)\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(trial.suggest_int(f\"hidden_layer_sizes_{i}\", 1, 128, step=10))\n",
    "    \n",
    "        neural = {\n",
    "            # 'hidden_layer_sizes': [layers],\n",
    "            'activation': trial.suggest_categorical(\"activation\", choices=['identity', 'logistic', 'tanh', 'relu']),\n",
    "            'solver': trial.suggest_categorical(\"solver\", choices=['sgd', 'adam', 'lbfgs']),\n",
    "            'alpha': trial.suggest_float(\"alpha\", 0.0001, 0.05),\n",
    "            'max_iter': trial.suggest_int(\"max_iter\", 200, 1000),\n",
    "            'learning_rate': trial.suggest_categorical(\"learning_rate\", choices=['constant','adaptive'])\n",
    "        }\n",
    "        \n",
    "        pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", MLPClassifier(**neural, random_state=seed))])\n",
    "\n",
    "    kfold = KFold(n_splits=5)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_indices, test_indices in kfold.split(train):\n",
    "        xtrain, ytrain = train.iloc[train_indices], y_train.iloc[train_indices] \n",
    "        x_test, y_test = train.iloc[test_indices], y_train.iloc[test_indices]\n",
    "        \n",
    "        pipe.fit(xtrain, ytrain)\n",
    "        y_pred = pipe.predict(x_test)\n",
    "            \n",
    "        fold_accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(fold_accuracy)\n",
    "        \n",
    "    return -1 * np.mean(accuracies)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 22:23:16,728]\u001b[0m A new study created in memory with name: no-name-e099f23d-cab0-4e9b-8b55-f1f88896e8d5\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:23:34,810]\u001b[0m Trial 0 finished with value: -0.8106372500738697 and parameters: {'bootstrap': 'gini', 'max_depth': 19, 'max_features': 0.08066459662806662, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1853, 'criterion': 'gini'}. Best is trial 0 with value: -0.8106372500738697.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:23:49,105]\u001b[0m Trial 1 finished with value: -0.8414360287599724 and parameters: {'bootstrap': 'entropy', 'max_depth': 12, 'max_features': 0.736606572320331, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1359, 'criterion': 'gini'}. Best is trial 1 with value: -0.8414360287599724.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:23:58,198]\u001b[0m Trial 2 finished with value: -0.8442332315571752 and parameters: {'bootstrap': 'gini', 'max_depth': 14, 'max_features': 0.7655102866529483, 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 871, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:24:12,510]\u001b[0m Trial 3 finished with value: -0.8302176696542893 and parameters: {'bootstrap': 'gini', 'max_depth': 6, 'max_features': 0.5213364398363869, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1415, 'criterion': 'gini'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:24:24,132]\u001b[0m Trial 4 finished with value: -0.8274500147739584 and parameters: {'bootstrap': 'entropy', 'max_depth': 16, 'max_features': 0.2825202582244543, 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 1143, 'criterion': 'gini'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:24:38,349]\u001b[0m Trial 5 finished with value: -0.8120161528612233 and parameters: {'bootstrap': 'gini', 'max_depth': 18, 'max_features': 0.16106011582600682, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1382, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:24:51,442]\u001b[0m Trial 6 finished with value: -0.8302373682655373 and parameters: {'bootstrap': 'gini', 'max_depth': 19, 'max_features': 0.2772063547905287, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1278, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:25:04,476]\u001b[0m Trial 7 finished with value: -0.8078400472766669 and parameters: {'bootstrap': 'gini', 'max_depth': 5, 'max_features': 0.071433015290581, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1287, 'criterion': 'gini'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:25:20,361]\u001b[0m Trial 8 finished with value: -0.8428444794641978 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.927550433445367, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 1524, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:25:36,359]\u001b[0m Trial 9 finished with value: -0.8288289175613119 and parameters: {'bootstrap': 'gini', 'max_depth': 14, 'max_features': 0.894976827096489, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1526, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:25:42,614]\u001b[0m Trial 10 finished with value: -0.8372303752585444 and parameters: {'bootstrap': 'entropy', 'max_depth': 9, 'max_features': 0.6559453062295574, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 593, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:25:49,517]\u001b[0m Trial 11 finished with value: -0.8245838668373879 and parameters: {'bootstrap': 'entropy', 'max_depth': 15, 'max_features': 0.9540754127159686, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 652, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:25:58,758]\u001b[0m Trial 12 finished with value: -0.8372402245641682 and parameters: {'bootstrap': 'entropy', 'max_depth': 10, 'max_features': 0.815375933434966, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 869, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:26:01,115]\u001b[0m Trial 13 finished with value: -0.8358219245543189 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.9970179184833918, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 206, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:26:19,112]\u001b[0m Trial 14 finished with value: -0.8372599231754162 and parameters: {'bootstrap': 'entropy', 'max_depth': 13, 'max_features': 0.5789639692065941, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1748, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:26:29,442]\u001b[0m Trial 15 finished with value: -0.8288289175613119 and parameters: {'bootstrap': 'gini', 'max_depth': 17, 'max_features': 0.7644324652901471, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 980, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:26:46,922]\u001b[0m Trial 16 finished with value: -0.8358219245543188 and parameters: {'bootstrap': 'gini', 'max_depth': 8, 'max_features': 0.8471267047539063, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1685, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:27:07,485]\u001b[0m Trial 17 finished with value: -0.8344528710725893 and parameters: {'bootstrap': 'entropy', 'max_depth': 11, 'max_features': 0.40932966048276664, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1972, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:27:14,864]\u001b[0m Trial 18 finished with value: -0.8232739091894021 and parameters: {'bootstrap': 'entropy', 'max_depth': 3, 'max_features': 0.707539119327951, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 724, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:27:18,839]\u001b[0m Trial 19 finished with value: -0.8330345710627401 and parameters: {'bootstrap': 'gini', 'max_depth': 16, 'max_features': 0.6278949308210625, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 368, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:27:29,428]\u001b[0m Trial 20 finished with value: -0.8343937752388456 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.9050008004084321, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1010, 'criterion': 'entropy'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:27:46,096]\u001b[0m Trial 21 finished with value: -0.8316261203585148 and parameters: {'bootstrap': 'entropy', 'max_depth': 12, 'max_features': 0.758645204487115, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1612, 'criterion': 'gini'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:27:58,270]\u001b[0m Trial 22 finished with value: -0.8386388259627697 and parameters: {'bootstrap': 'entropy', 'max_depth': 13, 'max_features': 0.8134708877735837, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1183, 'criterion': 'gini'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:28:13,404]\u001b[0m Trial 23 finished with value: -0.8358317738599428 and parameters: {'bootstrap': 'entropy', 'max_depth': 8, 'max_features': 0.46721765480534216, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1499, 'criterion': 'gini'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:28:22,081]\u001b[0m Trial 24 finished with value: -0.8385994287402736 and parameters: {'bootstrap': 'entropy', 'max_depth': 11, 'max_features': 0.7072586417497199, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 825, 'criterion': 'gini'}. Best is trial 2 with value: -0.8442332315571752.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:28:32,794]\u001b[0m Trial 25 finished with value: -0.8442430808627993 and parameters: {'bootstrap': 'entropy', 'max_depth': 14, 'max_features': 0.8925526500572516, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1025, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:28:43,173]\u001b[0m Trial 26 finished with value: -0.8358317738599428 and parameters: {'bootstrap': 'gini', 'max_depth': 15, 'max_features': 0.9195359433655725, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 985, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:28:48,822]\u001b[0m Trial 27 finished with value: -0.8302472175711613 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.9953199597908328, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 522, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:28:57,836]\u001b[0m Trial 28 finished with value: -0.8386289766571456 and parameters: {'bootstrap': 'gini', 'max_depth': 14, 'max_features': 0.8664475666939804, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 850, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:29:09,482]\u001b[0m Trial 29 finished with value: -0.8386289766571456 and parameters: {'bootstrap': 'gini', 'max_depth': 17, 'max_features': 0.8102695305943837, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1109, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:29:29,515]\u001b[0m Trial 30 finished with value: -0.8428543287698217 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.6207093937792143, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1977, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:29:48,555]\u001b[0m Trial 31 finished with value: -0.8316261203585148 and parameters: {'bootstrap': 'entropy', 'max_depth': 19, 'max_features': 0.6265825129877096, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1858, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:30:08,644]\u001b[0m Trial 32 finished with value: -0.840047276666995 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.5479701695721887, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1945, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:30:27,275]\u001b[0m Trial 33 finished with value: -0.840027578055747 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.6890139895390918, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1795, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:30:40,277]\u001b[0m Trial 34 finished with value: -0.8330247217571161 and parameters: {'bootstrap': 'entropy', 'max_depth': 16, 'max_features': 0.7769230001565716, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1222, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:30:55,423]\u001b[0m Trial 35 finished with value: -0.8400374273613711 and parameters: {'bootstrap': 'entropy', 'max_depth': 17, 'max_features': 0.45789493743078147, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1490, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:31:06,555]\u001b[0m Trial 36 finished with value: -0.8315965724416428 and parameters: {'bootstrap': 'entropy', 'max_depth': 14, 'max_features': 0.9323077353660048, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1058, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:31:20,512]\u001b[0m Trial 37 finished with value: -0.8330050231458681 and parameters: {'bootstrap': 'gini', 'max_depth': 19, 'max_features': 0.861238647427216, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1336, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:31:37,149]\u001b[0m Trial 38 finished with value: -0.8372500738697923 and parameters: {'bootstrap': 'gini', 'max_depth': 15, 'max_features': 0.7284466739500642, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1597, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:31:51,309]\u001b[0m Trial 39 finished with value: -0.8372599231754162 and parameters: {'bootstrap': 'entropy', 'max_depth': 13, 'max_features': 0.3807613685825545, 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 1395, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:32:00,746]\u001b[0m Trial 40 finished with value: -0.8372205259529203 and parameters: {'bootstrap': 'gini', 'max_depth': 18, 'max_features': 0.5857311684292957, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 910, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:32:13,799]\u001b[0m Trial 41 finished with value: -0.8050231458682162 and parameters: {'bootstrap': 'entropy', 'max_depth': 12, 'max_features': 0.13417969422473203, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1276, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:32:21,343]\u001b[0m Trial 42 finished with value: -0.8330148724514922 and parameters: {'bootstrap': 'entropy', 'max_depth': 10, 'max_features': 0.6672411980980589, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 723, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:32:33,359]\u001b[0m Trial 43 finished with value: -0.8372599231754162 and parameters: {'bootstrap': 'entropy', 'max_depth': 14, 'max_features': 0.9567487998892658, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1151, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:32:52,360]\u001b[0m Trial 44 finished with value: -0.8358317738599428 and parameters: {'bootstrap': 'entropy', 'max_depth': 16, 'max_features': 0.7483327348508562, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1872, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:33:07,020]\u001b[0m Trial 45 finished with value: -0.807840047276667 and parameters: {'bootstrap': 'entropy', 'max_depth': 10, 'max_features': 0.019187427090248843, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1456, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:33:24,191]\u001b[0m Trial 46 finished with value: -0.8302078203486654 and parameters: {'bootstrap': 'entropy', 'max_depth': 17, 'max_features': 0.8044159500898856, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1648, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:33:42,278]\u001b[0m Trial 47 finished with value: -0.8302275189599133 and parameters: {'bootstrap': 'gini', 'max_depth': 12, 'max_features': 0.8634123986346434, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 1747, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:33:49,992]\u001b[0m Trial 48 finished with value: -0.8260317147641091 and parameters: {'bootstrap': 'entropy', 'max_depth': 13, 'max_features': 0.27090814585576845, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 756, 'criterion': 'gini'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:33:59,683]\u001b[0m Trial 49 finished with value: -0.8414261794543485 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.6057447840422756, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 929, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:34:13,615]\u001b[0m Trial 50 finished with value: -0.8204176105584555 and parameters: {'bootstrap': 'gini', 'max_depth': 15, 'max_features': 0.5478161008053437, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1327, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:34:23,271]\u001b[0m Trial 51 finished with value: -0.8386388259627695 and parameters: {'bootstrap': 'entropy', 'max_depth': 19, 'max_features': 0.6200283818714168, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 927, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:34:34,586]\u001b[0m Trial 52 finished with value: -0.8386092780458979 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.6552821326203245, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1079, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:34:41,276]\u001b[0m Trial 53 finished with value: -0.8372205259529203 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.5045477411130862, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 640, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:34:52,166]\u001b[0m Trial 54 finished with value: -0.8344134738500936 and parameters: {'bootstrap': 'entropy', 'max_depth': 19, 'max_features': 0.7838052802444525, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1058, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:35:04,848]\u001b[0m Trial 55 finished with value: -0.8358317738599428 and parameters: {'bootstrap': 'entropy', 'max_depth': 6, 'max_features': 0.9600312867090355, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1241, 'criterion': 'entropy'}. Best is trial 25 with value: -0.8442430808627993.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:35:15,005]\u001b[0m Trial 56 finished with value: -0.8470501329656258 and parameters: {'bootstrap': 'entropy', 'max_depth': 11, 'max_features': 0.7281337631321794, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 964, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:35:20,443]\u001b[0m Trial 57 finished with value: -0.8358317738599428 and parameters: {'bootstrap': 'entropy', 'max_depth': 9, 'max_features': 0.8314258809382254, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 507, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:35:31,055]\u001b[0m Trial 58 finished with value: -0.8344331724613415 and parameters: {'bootstrap': 'gini', 'max_depth': 11, 'max_features': 0.8827101349172904, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1018, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:35:39,215]\u001b[0m Trial 59 finished with value: -0.8316359696641387 and parameters: {'bootstrap': 'entropy', 'max_depth': 9, 'max_features': 0.7339308208001998, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 778, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:35:51,213]\u001b[0m Trial 60 finished with value: -0.8330148724514922 and parameters: {'bootstrap': 'entropy', 'max_depth': 11, 'max_features': 0.6835924803744765, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1158, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:36:00,623]\u001b[0m Trial 61 finished with value: -0.83303457106274 and parameters: {'bootstrap': 'entropy', 'max_depth': 12, 'max_features': 0.5978620379379779, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 907, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:36:10,579]\u001b[0m Trial 62 finished with value: -0.8302373682655373 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.65130983874664, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 949, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:36:18,924]\u001b[0m Trial 63 finished with value: -0.8358416231655669 and parameters: {'bootstrap': 'entropy', 'max_depth': 13, 'max_features': 0.7187864109089226, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 812, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:36:35,096]\u001b[0m Trial 64 finished with value: -0.8372599231754162 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.7770829007746789, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1560, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:36:45,425]\u001b[0m Trial 65 finished with value: -0.8343839259332217 and parameters: {'bootstrap': 'entropy', 'max_depth': 15, 'max_features': 0.9094313525440426, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 985, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:37:03,232]\u001b[0m Trial 66 finished with value: -0.8329951738402442 and parameters: {'bootstrap': 'entropy', 'max_depth': 16, 'max_features': 0.8300553981939678, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 1712, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:37:14,784]\u001b[0m Trial 67 finished with value: -0.8316359696641387 and parameters: {'bootstrap': 'gini', 'max_depth': 18, 'max_features': 0.694093961109201, 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 1111, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:37:27,270]\u001b[0m Trial 68 finished with value: -0.8372106766472964 and parameters: {'bootstrap': 'entropy', 'max_depth': 14, 'max_features': 0.5469052773800771, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 1208, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:37:36,603]\u001b[0m Trial 69 finished with value: -0.8330247217571161 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.9895128496232848, 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 895, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:37:56,745]\u001b[0m Trial 70 finished with value: -0.8316359696641387 and parameters: {'bootstrap': 'gini', 'max_depth': 8, 'max_features': 0.6296344007938356, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1998, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:38:16,261]\u001b[0m Trial 71 finished with value: -0.8330345710627401 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.5150164318565766, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1921, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:38:36,248]\u001b[0m Trial 72 finished with value: -0.833054269673988 and parameters: {'bootstrap': 'entropy', 'max_depth': 19, 'max_features': 0.5589545533043054, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1941, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:38:54,870]\u001b[0m Trial 73 finished with value: -0.8274401654683345 and parameters: {'bootstrap': 'entropy', 'max_depth': 19, 'max_features': 0.41915479058101424, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1828, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:39:14,554]\u001b[0m Trial 74 finished with value: -0.8372599231754162 and parameters: {'bootstrap': 'entropy', 'max_depth': 17, 'max_features': 0.61222606296174, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1909, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:39:25,297]\u001b[0m Trial 75 finished with value: -0.8316261203585146 and parameters: {'bootstrap': 'entropy', 'max_depth': 16, 'max_features': 0.49626663490696005, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1031, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:39:43,705]\u001b[0m Trial 76 finished with value: -0.8316064217472668 and parameters: {'bootstrap': 'entropy', 'max_depth': 12, 'max_features': 0.7558299846058701, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1769, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:40:00,908]\u001b[0m Trial 77 finished with value: -0.8386388259627697 and parameters: {'bootstrap': 'entropy', 'max_depth': 10, 'max_features': 0.8951147911217734, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1662, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:40:15,638]\u001b[0m Trial 78 finished with value: -0.8302275189599133 and parameters: {'bootstrap': 'entropy', 'max_depth': 14, 'max_features': 0.7979881308815135, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1441, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:40:24,658]\u001b[0m Trial 79 finished with value: -0.8344528710725893 and parameters: {'bootstrap': 'gini', 'max_depth': 17, 'max_features': 0.6473969209181728, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 864, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:40:38,609]\u001b[0m Trial 80 finished with value: -0.8414458780655962 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.573434368370048, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1344, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:40:52,748]\u001b[0m Trial 81 finished with value: -0.8330247217571161 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.5720602809093585, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1367, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:41:08,669]\u001b[0m Trial 82 finished with value: -0.8316261203585148 and parameters: {'bootstrap': 'entropy', 'max_depth': 19, 'max_features': 0.5964824042812747, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1553, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:41:18,409]\u001b[0m Trial 83 finished with value: -0.8064315965724417 and parameters: {'bootstrap': 'entropy', 'max_depth': 3, 'max_features': 0.5317845673021124, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 964, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:41:31,556]\u001b[0m Trial 84 finished with value: -0.8386289766571456 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.476533084199242, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1286, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:41:45,328]\u001b[0m Trial 85 finished with value: -0.8372402245641682 and parameters: {'bootstrap': 'entropy', 'max_depth': 11, 'max_features': 0.9257632926706156, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1337, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:42:00,652]\u001b[0m Trial 86 finished with value: -0.8288190682556879 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.6841357868191101, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1489, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:42:12,042]\u001b[0m Trial 87 finished with value: -0.828809218950064 and parameters: {'bootstrap': 'gini', 'max_depth': 17, 'max_features': 0.44061054614900796, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1110, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:42:19,603]\u001b[0m Trial 88 finished with value: -0.8330247217571161 and parameters: {'bootstrap': 'entropy', 'max_depth': 13, 'max_features': 0.8428575756529908, 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 710, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:42:28,529]\u001b[0m Trial 89 finished with value: -0.8330247217571161 and parameters: {'bootstrap': 'entropy', 'max_depth': 15, 'max_features': 0.7418460484961228, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 845, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:42:41,450]\u001b[0m Trial 90 finished with value: -0.833054269673988 and parameters: {'bootstrap': 'entropy', 'max_depth': 19, 'max_features': 0.5829623451975097, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1246, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:42:56,041]\u001b[0m Trial 91 finished with value: -0.8344627203782133 and parameters: {'bootstrap': 'entropy', 'max_depth': 16, 'max_features': 0.396851684505401, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1425, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:43:10,139]\u001b[0m Trial 92 finished with value: -0.8358317738599428 and parameters: {'bootstrap': 'entropy', 'max_depth': 17, 'max_features': 0.36506059008534786, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1391, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:43:25,478]\u001b[0m Trial 93 finished with value: -0.8302275189599133 and parameters: {'bootstrap': 'entropy', 'max_depth': 20, 'max_features': 0.3420701988930561, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1519, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:43:42,122]\u001b[0m Trial 94 finished with value: -0.8386388259627695 and parameters: {'bootstrap': 'entropy', 'max_depth': 19, 'max_features': 0.47196312199504964, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1624, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:43:56,780]\u001b[0m Trial 95 finished with value: -0.8358416231655669 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.5293788774628548, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1483, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:44:15,702]\u001b[0m Trial 96 finished with value: -0.8358317738599428 and parameters: {'bootstrap': 'entropy', 'max_depth': 18, 'max_features': 0.6371250197895739, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 1879, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:44:31,135]\u001b[0m Trial 97 finished with value: -0.8372008273416724 and parameters: {'bootstrap': 'gini', 'max_depth': 17, 'max_features': 0.7158758202819892, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1559, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:44:49,258]\u001b[0m Trial 98 finished with value: -0.8344233231557174 and parameters: {'bootstrap': 'entropy', 'max_depth': 12, 'max_features': 0.9743910909610692, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1815, 'criterion': 'gini'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:44:51,475]\u001b[0m Trial 99 finished with value: -0.8344036245444695 and parameters: {'bootstrap': 'entropy', 'max_depth': 13, 'max_features': 0.6721345208633623, 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 200, 'criterion': 'entropy'}. Best is trial 56 with value: -0.8470501329656258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================================\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from functools import partial\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# for name, classifier in tmp_classifiers.items():\n",
    "# for model in [\"rf\", \"logit\"]:\n",
    "optimization_function = partial(optimization_step, name=\"rf\", train=train, y_train=y_train)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(optimization_function, n_trials=100)\n",
    "    \n",
    "print(\"=========================================================================================================================\")\n",
    "rf = study.best_params\n",
    "print(\"=========================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 22:44:51,565]\u001b[0m A new study created in memory with name: no-name-ddea466d-7b7f-4b57-b6ad-c72092ec7b87\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:44:53,179]\u001b[0m Trial 0 finished with value: -0.8162218063626515 and parameters: {'n_estimators': 1192, 'learning_rate': 0.15971146437091957, 'num_leaves': 120, 'max_depth': 4}. Best is trial 0 with value: -0.8162218063626515.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:44:54,581]\u001b[0m Trial 1 finished with value: -0.8273909189402147 and parameters: {'n_estimators': 454, 'learning_rate': 0.034003218477783884, 'num_leaves': 60, 'max_depth': 19}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:44:56,587]\u001b[0m Trial 2 finished with value: -0.8260218654584852 and parameters: {'n_estimators': 876, 'learning_rate': 0.10495027814448395, 'num_leaves': 60, 'max_depth': 8}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:01,276]\u001b[0m Trial 3 finished with value: -0.8176007091500048 and parameters: {'n_estimators': 1990, 'learning_rate': 0.056730018371589655, 'num_leaves': 40, 'max_depth': 9}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:04,060]\u001b[0m Trial 4 finished with value: -0.8260218654584852 and parameters: {'n_estimators': 940, 'learning_rate': 0.04959394514242338, 'num_leaves': 80, 'max_depth': 15}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:05,837]\u001b[0m Trial 5 finished with value: -0.8134344528710727 and parameters: {'n_estimators': 627, 'learning_rate': 0.26815888288011214, 'num_leaves': 100, 'max_depth': 17}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:09,748]\u001b[0m Trial 6 finished with value: -0.817571161233133 and parameters: {'n_estimators': 1541, 'learning_rate': 0.07375257331547605, 'num_leaves': 20, 'max_depth': 15}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:14,266]\u001b[0m Trial 7 finished with value: -0.8035752979414952 and parameters: {'n_estimators': 1827, 'learning_rate': 0.25169956127497306, 'num_leaves': 40, 'max_depth': 15}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:14,806]\u001b[0m Trial 8 finished with value: -0.8246134147542599 and parameters: {'n_estimators': 506, 'learning_rate': 0.01358960429703825, 'num_leaves': 100, 'max_depth': 3}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:18,696]\u001b[0m Trial 9 finished with value: -0.8148527528809218 and parameters: {'n_estimators': 1465, 'learning_rate': 0.1266715595819726, 'num_leaves': 40, 'max_depth': 13}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:19,414]\u001b[0m Trial 10 finished with value: -0.8260612626809809 and parameters: {'n_estimators': 227, 'learning_rate': 0.18741413671261914, 'num_leaves': 80, 'max_depth': 19}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:20,144]\u001b[0m Trial 11 finished with value: -0.8232049640500344 and parameters: {'n_estimators': 231, 'learning_rate': 0.1933725727092248, 'num_leaves': 80, 'max_depth': 20}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:20,799]\u001b[0m Trial 12 finished with value: -0.8175613119275091 and parameters: {'n_estimators': 208, 'learning_rate': 0.19805272309117533, 'num_leaves': 60, 'max_depth': 20}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:22,276]\u001b[0m Trial 13 finished with value: -0.8218063626514331 and parameters: {'n_estimators': 525, 'learning_rate': 0.21553563251692207, 'num_leaves': 80, 'max_depth': 18}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:24,270]\u001b[0m Trial 14 finished with value: -0.8245937161430119 and parameters: {'n_estimators': 685, 'learning_rate': 0.1530737422229767, 'num_leaves': 100, 'max_depth': 18}. Best is trial 1 with value: -0.8273909189402147.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:25,456]\u001b[0m Trial 15 finished with value: -0.8287993696444401 and parameters: {'n_estimators': 375, 'learning_rate': 0.013674773303365417, 'num_leaves': 60, 'max_depth': 11}. Best is trial 15 with value: -0.8287993696444401.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:26,469]\u001b[0m Trial 16 finished with value: -0.8372205259529203 and parameters: {'n_estimators': 428, 'learning_rate': 0.023751368654697798, 'num_leaves': 20, 'max_depth': 10}. Best is trial 16 with value: -0.8372205259529203.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:28,410]\u001b[0m Trial 17 finished with value: -0.8386289766571456 and parameters: {'n_estimators': 830, 'learning_rate': 0.01034381492236076, 'num_leaves': 20, 'max_depth': 10}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:29,984]\u001b[0m Trial 18 finished with value: -0.8316359696641387 and parameters: {'n_estimators': 858, 'learning_rate': 0.09698949778022975, 'num_leaves': 20, 'max_depth': 6}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:32,523]\u001b[0m Trial 19 finished with value: -0.8231754161331626 and parameters: {'n_estimators': 1087, 'learning_rate': 0.0832427537475336, 'num_leaves': 20, 'max_depth': 11}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:35,376]\u001b[0m Trial 20 finished with value: -0.8246035654486359 and parameters: {'n_estimators': 1268, 'learning_rate': 0.03903216220423098, 'num_leaves': 20, 'max_depth': 9}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:36,881]\u001b[0m Trial 21 finished with value: -0.8274007682458387 and parameters: {'n_estimators': 818, 'learning_rate': 0.09567422445025628, 'num_leaves': 20, 'max_depth': 6}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:38,504]\u001b[0m Trial 22 finished with value: -0.8204471584753275 and parameters: {'n_estimators': 739, 'learning_rate': 0.1262294765422908, 'num_leaves': 40, 'max_depth': 7}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:40,112]\u001b[0m Trial 23 finished with value: -0.8302570668767852 and parameters: {'n_estimators': 1004, 'learning_rate': 0.06574678648148144, 'num_leaves': 20, 'max_depth': 5}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:43,636]\u001b[0m Trial 24 finished with value: -0.8232640598837782 and parameters: {'n_estimators': 1355, 'learning_rate': 0.026835470099631192, 'num_leaves': 40, 'max_depth': 10}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:45,504]\u001b[0m Trial 25 finished with value: -0.8203880626415838 and parameters: {'n_estimators': 788, 'learning_rate': 0.11312380429510088, 'num_leaves': 20, 'max_depth': 13}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:46,771]\u001b[0m Trial 26 finished with value: -0.8316261203585148 and parameters: {'n_estimators': 601, 'learning_rate': 0.05171756638732119, 'num_leaves': 40, 'max_depth': 7}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:47,978]\u001b[0m Trial 27 finished with value: -0.8246134147542599 and parameters: {'n_estimators': 389, 'learning_rate': 0.08417452719486099, 'num_leaves': 20, 'max_depth': 13}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:50,454]\u001b[0m Trial 28 finished with value: -0.8274303161627106 and parameters: {'n_estimators': 1051, 'learning_rate': 0.025085349792161232, 'num_leaves': 20, 'max_depth': 9}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:52,197]\u001b[0m Trial 29 finished with value: -0.8147542598246824 and parameters: {'n_estimators': 1111, 'learning_rate': 0.15272956860102463, 'num_leaves': 120, 'max_depth': 5}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:53,022]\u001b[0m Trial 30 finished with value: -0.8372500738697923 and parameters: {'n_estimators': 890, 'learning_rate': 0.010442526348137518, 'num_leaves': 40, 'max_depth': 3}. Best is trial 17 with value: -0.8386289766571456.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:54,012]\u001b[0m Trial 31 finished with value: -0.8400472766669951 and parameters: {'n_estimators': 915, 'learning_rate': 0.014690402549637287, 'num_leaves': 40, 'max_depth': 3}. Best is trial 31 with value: -0.8400472766669951.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:55,031]\u001b[0m Trial 32 finished with value: -0.8288289175613119 and parameters: {'n_estimators': 1150, 'learning_rate': 0.011701055939532497, 'num_leaves': 40, 'max_depth': 3}. Best is trial 31 with value: -0.8400472766669951.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:56,529]\u001b[0m Trial 33 finished with value: -0.8260612626809811 and parameters: {'n_estimators': 939, 'learning_rate': 0.04058513890824234, 'num_leaves': 60, 'max_depth': 5}. Best is trial 31 with value: -0.8400472766669951.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:58,147]\u001b[0m Trial 34 finished with value: -0.8428444794641978 and parameters: {'n_estimators': 1229, 'learning_rate': 0.03023609986907551, 'num_leaves': 40, 'max_depth': 4}. Best is trial 34 with value: -0.8428444794641978.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:45:59,754]\u001b[0m Trial 35 finished with value: -0.828858465478184 and parameters: {'n_estimators': 1250, 'learning_rate': 0.0617994394337321, 'num_leaves': 60, 'max_depth': 4}. Best is trial 34 with value: -0.8428444794641978.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:00,678]\u001b[0m Trial 36 finished with value: -0.8372402245641682 and parameters: {'n_estimators': 978, 'learning_rate': 0.0404585475123167, 'num_leaves': 40, 'max_depth': 3}. Best is trial 34 with value: -0.8428444794641978.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:02,665]\u001b[0m Trial 37 finished with value: -0.817590859844381 and parameters: {'n_estimators': 1663, 'learning_rate': 0.051789075944204635, 'num_leaves': 40, 'max_depth': 4}. Best is trial 34 with value: -0.8428444794641978.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:05,684]\u001b[0m Trial 38 finished with value: -0.8218260612626811 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0318926464865323, 'num_leaves': 60, 'max_depth': 7}. Best is trial 34 with value: -0.8428444794641978.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:07,260]\u001b[0m Trial 39 finished with value: -0.8316655175810105 and parameters: {'n_estimators': 1202, 'learning_rate': 0.010482325627358763, 'num_leaves': 40, 'max_depth': 4}. Best is trial 34 with value: -0.8428444794641978.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:08,078]\u001b[0m Trial 40 finished with value: -0.833064118979612 and parameters: {'n_estimators': 895, 'learning_rate': 0.0777828763356715, 'num_leaves': 40, 'max_depth': 3}. Best is trial 34 with value: -0.8428444794641978.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:08,951]\u001b[0m Trial 41 finished with value: -0.8344233231557174 and parameters: {'n_estimators': 962, 'learning_rate': 0.0444240073862393, 'num_leaves': 40, 'max_depth': 3}. Best is trial 34 with value: -0.8428444794641978.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:09,778]\u001b[0m Trial 42 finished with value: -0.8442529301684232 and parameters: {'n_estimators': 651, 'learning_rate': 0.033428873931454425, 'num_leaves': 60, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:11,104]\u001b[0m Trial 43 finished with value: -0.8386683738796414 and parameters: {'n_estimators': 662, 'learning_rate': 0.027211098702407198, 'num_leaves': 60, 'max_depth': 6}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:12,338]\u001b[0m Trial 44 finished with value: -0.8246232640598837 and parameters: {'n_estimators': 628, 'learning_rate': 0.06582948198544668, 'num_leaves': 60, 'max_depth': 6}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:13,625]\u001b[0m Trial 45 finished with value: -0.8400374273613711 and parameters: {'n_estimators': 722, 'learning_rate': 0.028378450344858724, 'num_leaves': 60, 'max_depth': 5}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:14,780]\u001b[0m Trial 46 finished with value: -0.8400177287501231 and parameters: {'n_estimators': 713, 'learning_rate': 0.027925372853279402, 'num_leaves': 60, 'max_depth': 5}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:15,613]\u001b[0m Trial 47 finished with value: -0.8217965133458092 and parameters: {'n_estimators': 523, 'learning_rate': 0.24286803285806807, 'num_leaves': 80, 'max_depth': 5}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:16,562]\u001b[0m Trial 48 finished with value: -0.8316359696641387 and parameters: {'n_estimators': 776, 'learning_rate': 0.05688807912193927, 'num_leaves': 60, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:17,339]\u001b[0m Trial 49 finished with value: -0.8161922584457797 and parameters: {'n_estimators': 313, 'learning_rate': 0.07221892724540406, 'num_leaves': 80, 'max_depth': 8}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:18,523]\u001b[0m Trial 50 finished with value: -0.8344233231557174 and parameters: {'n_estimators': 717, 'learning_rate': 0.033837082668053416, 'num_leaves': 60, 'max_depth': 5}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:19,343]\u001b[0m Trial 51 finished with value: -0.8414360287599724 and parameters: {'n_estimators': 642, 'learning_rate': 0.023817285113512606, 'num_leaves': 60, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:20,123]\u001b[0m Trial 52 finished with value: -0.835831773859943 and parameters: {'n_estimators': 606, 'learning_rate': 0.022854497163446515, 'num_leaves': 60, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:20,957]\u001b[0m Trial 53 finished with value: -0.8302373682655373 and parameters: {'n_estimators': 539, 'learning_rate': 0.048602163368717186, 'num_leaves': 60, 'max_depth': 5}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:22,566]\u001b[0m Trial 54 finished with value: -0.8316458189697628 and parameters: {'n_estimators': 746, 'learning_rate': 0.021416809401706198, 'num_leaves': 80, 'max_depth': 6}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:23,235]\u001b[0m Trial 55 finished with value: -0.8176302570668768 and parameters: {'n_estimators': 468, 'learning_rate': 0.292075109108421, 'num_leaves': 80, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:24,876]\u001b[0m Trial 56 finished with value: -0.8245838668373879 and parameters: {'n_estimators': 682, 'learning_rate': 0.03658569225794358, 'num_leaves': 60, 'max_depth': 8}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:27,234]\u001b[0m Trial 57 finished with value: -0.817571161233133 and parameters: {'n_estimators': 1047, 'learning_rate': 0.053997083048879235, 'num_leaves': 60, 'max_depth': 7}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:27,950]\u001b[0m Trial 58 finished with value: -0.8372697724810401 and parameters: {'n_estimators': 564, 'learning_rate': 0.023115737067931862, 'num_leaves': 60, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:28,759]\u001b[0m Trial 59 finished with value: -0.83303457106274 and parameters: {'n_estimators': 872, 'learning_rate': 0.08766861684017714, 'num_leaves': 100, 'max_depth': 3}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:31,578]\u001b[0m Trial 60 finished with value: -0.8203880626415838 and parameters: {'n_estimators': 1542, 'learning_rate': 0.04550804090621037, 'num_leaves': 80, 'max_depth': 6}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:32,918]\u001b[0m Trial 61 finished with value: -0.8190387077711021 and parameters: {'n_estimators': 677, 'learning_rate': 0.0330462478458048, 'num_leaves': 60, 'max_depth': 6}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:33,989]\u001b[0m Trial 62 finished with value: -0.8274106175514626 and parameters: {'n_estimators': 643, 'learning_rate': 0.020216455663755073, 'num_leaves': 60, 'max_depth': 5}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:36,449]\u001b[0m Trial 63 finished with value: -0.8260415640697332 and parameters: {'n_estimators': 828, 'learning_rate': 0.02932833048447852, 'num_leaves': 40, 'max_depth': 16}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:37,094]\u001b[0m Trial 64 finished with value: -0.8386782231852654 and parameters: {'n_estimators': 485, 'learning_rate': 0.0651184482385132, 'num_leaves': 60, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:37,447]\u001b[0m Trial 65 finished with value: -0.8428641780754458 and parameters: {'n_estimators': 289, 'learning_rate': 0.06895643365696233, 'num_leaves': 60, 'max_depth': 3}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:37,784]\u001b[0m Trial 66 finished with value: -0.8372402245641682 and parameters: {'n_estimators': 264, 'learning_rate': 0.16444194499432568, 'num_leaves': 80, 'max_depth': 3}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:38,284]\u001b[0m Trial 67 finished with value: -0.8358416231655669 and parameters: {'n_estimators': 398, 'learning_rate': 0.01846195177564325, 'num_leaves': 40, 'max_depth': 3}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:38,865]\u001b[0m Trial 68 finished with value: -0.8316261203585148 and parameters: {'n_estimators': 332, 'learning_rate': 0.04274309768281389, 'num_leaves': 40, 'max_depth': 5}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:40,841]\u001b[0m Trial 69 finished with value: -0.8078006500541711 and parameters: {'n_estimators': 1297, 'learning_rate': 0.11468523879329888, 'num_leaves': 60, 'max_depth': 5}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:41,771]\u001b[0m Trial 70 finished with value: -0.8330542696739881 and parameters: {'n_estimators': 770, 'learning_rate': 0.037463755780011, 'num_leaves': 60, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:42,374]\u001b[0m Trial 71 finished with value: -0.8358317738599428 and parameters: {'n_estimators': 454, 'learning_rate': 0.06936852243992245, 'num_leaves': 60, 'max_depth': 4}. Best is trial 42 with value: -0.8442529301684232.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:42,882]\u001b[0m Trial 72 finished with value: -0.8442726287796709 and parameters: {'n_estimators': 487, 'learning_rate': 0.05652777005237571, 'num_leaves': 60, 'max_depth': 3}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:44,802]\u001b[0m Trial 73 finished with value: -0.8316458189697625 and parameters: {'n_estimators': 1984, 'learning_rate': 0.05835303895163544, 'num_leaves': 60, 'max_depth': 3}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:45,381]\u001b[0m Trial 74 finished with value: -0.8330345710627401 and parameters: {'n_estimators': 569, 'learning_rate': 0.04863966889697063, 'num_leaves': 40, 'max_depth': 3}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:45,880]\u001b[0m Trial 75 finished with value: -0.8330148724514922 and parameters: {'n_estimators': 327, 'learning_rate': 0.01647033438394767, 'num_leaves': 80, 'max_depth': 4}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:46,648]\u001b[0m Trial 76 finished with value: -0.8302275189599133 and parameters: {'n_estimators': 716, 'learning_rate': 0.029686975034384284, 'num_leaves': 120, 'max_depth': 3}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:47,546]\u001b[0m Trial 77 finished with value: -0.8344430217669656 and parameters: {'n_estimators': 596, 'learning_rate': 0.057541869438240745, 'num_leaves': 60, 'max_depth': 5}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:47,977]\u001b[0m Trial 78 finished with value: -0.8414163301487244 and parameters: {'n_estimators': 274, 'learning_rate': 0.09130345095381284, 'num_leaves': 40, 'max_depth': 4}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:48,271]\u001b[0m Trial 79 finished with value: -0.8400177287501231 and parameters: {'n_estimators': 203, 'learning_rate': 0.0966363876647997, 'num_leaves': 40, 'max_depth': 3}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:48,694]\u001b[0m Trial 80 finished with value: -0.833054269673988 and parameters: {'n_estimators': 284, 'learning_rate': 0.10810629284914225, 'num_leaves': 40, 'max_depth': 4}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:49,343]\u001b[0m Trial 81 finished with value: -0.8260218654584852 and parameters: {'n_estimators': 208, 'learning_rate': 0.08980292602824788, 'num_leaves': 40, 'max_depth': 14}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:49,805]\u001b[0m Trial 82 finished with value: -0.8330148724514922 and parameters: {'n_estimators': 415, 'learning_rate': 0.07724932379981529, 'num_leaves': 40, 'max_depth': 3}. Best is trial 72 with value: -0.8442726287796709.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:50,292]\u001b[0m Trial 83 finished with value: -0.8540726878755048 and parameters: {'n_estimators': 350, 'learning_rate': 0.04256358404214131, 'num_leaves': 60, 'max_depth': 4}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:50,834]\u001b[0m Trial 84 finished with value: -0.8484487343642275 and parameters: {'n_estimators': 378, 'learning_rate': 0.037391318886383834, 'num_leaves': 60, 'max_depth': 4}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:51,354]\u001b[0m Trial 85 finished with value: -0.8428543287698217 and parameters: {'n_estimators': 367, 'learning_rate': 0.039374298072778105, 'num_leaves': 60, 'max_depth': 4}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:51,753]\u001b[0m Trial 86 finished with value: -0.8372106766472964 and parameters: {'n_estimators': 265, 'learning_rate': 0.07894687522615511, 'num_leaves': 60, 'max_depth': 4}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:53,019]\u001b[0m Trial 87 finished with value: -0.8316359696641387 and parameters: {'n_estimators': 428, 'learning_rate': 0.06352455909867923, 'num_leaves': 60, 'max_depth': 12}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:53,754]\u001b[0m Trial 88 finished with value: -0.8302570668767851 and parameters: {'n_estimators': 364, 'learning_rate': 0.04486283116697883, 'num_leaves': 60, 'max_depth': 6}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:54,351]\u001b[0m Trial 89 finished with value: -0.8470796808824979 and parameters: {'n_estimators': 365, 'learning_rate': 0.05273840909011603, 'num_leaves': 60, 'max_depth': 4}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:55,142]\u001b[0m Trial 90 finished with value: -0.8456416822614005 and parameters: {'n_estimators': 350, 'learning_rate': 0.05158795267153676, 'num_leaves': 60, 'max_depth': 7}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:55,919]\u001b[0m Trial 91 finished with value: -0.8316359696641387 and parameters: {'n_estimators': 355, 'learning_rate': 0.049959760480853405, 'num_leaves': 60, 'max_depth': 7}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:56,728]\u001b[0m Trial 92 finished with value: -0.8274007682458386 and parameters: {'n_estimators': 514, 'learning_rate': 0.03917460820270341, 'num_leaves': 60, 'max_depth': 5}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:57,270]\u001b[0m Trial 93 finished with value: -0.840047276666995 and parameters: {'n_estimators': 375, 'learning_rate': 0.05488027569124164, 'num_leaves': 60, 'max_depth': 4}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:57,868]\u001b[0m Trial 94 finished with value: -0.8428543287698218 and parameters: {'n_estimators': 442, 'learning_rate': 0.03553274122697454, 'num_leaves': 60, 'max_depth': 4}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:58,338]\u001b[0m Trial 95 finished with value: -0.8316458189697628 and parameters: {'n_estimators': 442, 'learning_rate': 0.07233494712123566, 'num_leaves': 60, 'max_depth': 3}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:59,133]\u001b[0m Trial 96 finished with value: -0.8400078794444992 and parameters: {'n_estimators': 304, 'learning_rate': 0.03523339483252711, 'num_leaves': 60, 'max_depth': 9}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:46:59,927]\u001b[0m Trial 97 finished with value: -0.8204274598640795 and parameters: {'n_estimators': 501, 'learning_rate': 0.05938505898813855, 'num_leaves': 80, 'max_depth': 5}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:47:00,734]\u001b[0m Trial 98 finished with value: -0.8442824780852949 and parameters: {'n_estimators': 397, 'learning_rate': 0.04220395596613732, 'num_leaves': 60, 'max_depth': 6}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:47:01,601]\u001b[0m Trial 99 finished with value: -0.8246331133655076 and parameters: {'n_estimators': 399, 'learning_rate': 0.049748172953528694, 'num_leaves': 60, 'max_depth': 7}. Best is trial 83 with value: -0.8540726878755048.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================================\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "optimization_function = partial(optimization_step, name=\"lgbm\", train=train, y_train=y_train)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(optimization_function, n_trials=100)\n",
    "    \n",
    "print(\"=========================================================================================================================\")\n",
    "lgbm = study.best_params\n",
    "print(\"=========================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-01 22:47:01,693]\u001b[0m A new study created in memory with name: no-name-994a60fb-63fd-4617-9d47-bf14eb46866f\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:47:05,082]\u001b[0m Trial 0 finished with value: -0.8105387570176303 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 61, 'hidden_layer_sizes_1': 71, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.024818840207004592, 'max_iter': 226, 'learning_rate': 'constant'}. Best is trial 0 with value: -0.8105387570176303.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:47:15,545]\u001b[0m Trial 1 finished with value: -0.8134049049542007 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 11, 'hidden_layer_sizes_1': 31, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.018229469978840396, 'max_iter': 398, 'learning_rate': 'adaptive'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:47:25,551]\u001b[0m Trial 2 finished with value: -0.8133753570373289 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 61, 'hidden_layer_sizes_1': 71, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.027068187385611255, 'max_iter': 509, 'learning_rate': 'adaptive'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:47:42,509]\u001b[0m Trial 3 finished with value: -0.8077317049148034 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 11, 'hidden_layer_sizes_1': 81, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.009625571534006337, 'max_iter': 841, 'learning_rate': 'adaptive'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:47:46,950]\u001b[0m Trial 4 finished with value: -0.789599133261105 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 81, 'activation': 'identity', 'solver': 'sgd', 'alpha': 0.00029186847825365795, 'max_iter': 353, 'learning_rate': 'constant'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:47:51,402]\u001b[0m Trial 5 finished with value: -0.8049345021176008 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 111, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.04734067429366547, 'max_iter': 305, 'learning_rate': 'constant'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:48:03,591]\u001b[0m Trial 6 finished with value: -0.8077711021372993 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 81, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.02494154467304036, 'max_iter': 853, 'learning_rate': 'constant'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:48:08,608]\u001b[0m Trial 7 finished with value: -0.7993991923569388 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 1, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.003968013845442616, 'max_iter': 207, 'learning_rate': 'adaptive'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:48:22,660]\u001b[0m Trial 8 finished with value: -0.8092091007583964 and parameters: {'hidden_layer_sizes': 4, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 11, 'hidden_layer_sizes_2': 51, 'hidden_layer_sizes_3': 91, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.004832332165282014, 'max_iter': 859, 'learning_rate': 'adaptive'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:48:30,628]\u001b[0m Trial 9 finished with value: -0.7825765783512264 and parameters: {'hidden_layer_sizes': 4, 'hidden_layer_sizes_0': 61, 'hidden_layer_sizes_1': 41, 'hidden_layer_sizes_2': 121, 'hidden_layer_sizes_3': 11, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.030476679764549066, 'max_iter': 431, 'learning_rate': 'constant'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:48:32,647]\u001b[0m Trial 10 finished with value: -0.7994188909681867 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 1, 'hidden_layer_sizes_1': 121, 'hidden_layer_sizes_2': 1, 'activation': 'identity', 'solver': 'adam', 'alpha': 0.014783479683232164, 'max_iter': 656, 'learning_rate': 'adaptive'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:48:46,760]\u001b[0m Trial 11 finished with value: -0.8063921993499459 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 21, 'hidden_layer_sizes_1': 41, 'hidden_layer_sizes_2': 121, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.03623425651794724, 'max_iter': 537, 'learning_rate': 'adaptive'}. Best is trial 1 with value: -0.8134049049542007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:48:58,942]\u001b[0m Trial 12 finished with value: -0.8162021077514033 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 31, 'hidden_layer_sizes_1': 41, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.017962209287436907, 'max_iter': 610, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:49:15,272]\u001b[0m Trial 13 finished with value: -0.8022160937653895 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 31, 'hidden_layer_sizes_1': 31, 'hidden_layer_sizes_2': 1, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.01717524400381499, 'max_iter': 702, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:49:24,950]\u001b[0m Trial 14 finished with value: -0.7811878262582488 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 1, 'hidden_layer_sizes_1': 21, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.017539540589491167, 'max_iter': 712, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:49:39,166]\u001b[0m Trial 15 finished with value: -0.8064118979611937 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 31, 'hidden_layer_sizes_1': 51, 'hidden_layer_sizes_2': 71, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.037719498820215455, 'max_iter': 570, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:49:58,694]\u001b[0m Trial 16 finished with value: -0.8035654486358711 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 21, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.012414794485841117, 'max_iter': 976, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:50:00,705]\u001b[0m Trial 17 finished with value: -0.7952132374667585 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 111, 'activation': 'identity', 'solver': 'adam', 'alpha': 0.021339146793935195, 'max_iter': 455, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:50:06,891]\u001b[0m Trial 18 finished with value: -0.8105683049345022 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 121, 'hidden_layer_sizes_1': 91, 'hidden_layer_sizes_2': 61, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.008959994443031616, 'max_iter': 425, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:50:16,448]\u001b[0m Trial 19 finished with value: -0.7769723234511968 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 81, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.020274223264499534, 'max_iter': 623, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:50:25,181]\u001b[0m Trial 20 finished with value: -0.8092091007583966 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 11, 'hidden_layer_sizes_1': 51, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.033045512625714986, 'max_iter': 332, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:50:35,342]\u001b[0m Trial 21 finished with value: -0.8049640500344726 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 101, 'hidden_layer_sizes_1': 61, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.02912283884487476, 'max_iter': 519, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:50:45,005]\u001b[0m Trial 22 finished with value: -0.8105584556288781 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 31, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.02230522976939949, 'max_iter': 486, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:50:59,138]\u001b[0m Trial 23 finished with value: -0.8077612528316754 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 71, 'hidden_layer_sizes_1': 91, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.04430450066362965, 'max_iter': 740, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:51:06,679]\u001b[0m Trial 24 finished with value: -0.8091500049246528 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 21, 'hidden_layer_sizes_1': 61, 'hidden_layer_sizes_2': 31, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.02797747332253265, 'max_iter': 379, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:51:18,503]\u001b[0m Trial 25 finished with value: -0.8063232542105782 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 21, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.01837040772970783, 'max_iter': 592, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:51:19,571]\u001b[0m Trial 26 finished with value: -0.7965724416428641 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 11, 'activation': 'identity', 'solver': 'lbfgs', 'alpha': 0.013613827458254218, 'max_iter': 508, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:51:29,225]\u001b[0m Trial 27 finished with value: -0.8050034472569683 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 31, 'hidden_layer_sizes_1': 71, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.03995474200092638, 'max_iter': 398, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:51:35,746]\u001b[0m Trial 28 finished with value: -0.7671722643553629 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 91, 'hidden_layer_sizes_1': 41, 'hidden_layer_sizes_2': 81, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.025488297629635715, 'max_iter': 299, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:51:39,395]\u001b[0m Trial 29 finished with value: -0.8077809514429232 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 1, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.03232476155928189, 'max_iter': 241, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:51:52,176]\u001b[0m Trial 30 finished with value: -0.8049738993400967 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 71, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.023712582566372896, 'max_iter': 650, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:51:59,131]\u001b[0m Trial 31 finished with value: -0.8105387570176303 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 121, 'hidden_layer_sizes_1': 101, 'hidden_layer_sizes_2': 91, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.00974575388245978, 'max_iter': 473, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:52:05,321]\u001b[0m Trial 32 finished with value: -0.8035162021077513 and parameters: {'hidden_layer_sizes': 4, 'hidden_layer_sizes_0': 121, 'hidden_layer_sizes_1': 91, 'hidden_layer_sizes_2': 41, 'hidden_layer_sizes_3': 121, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.008833787862963082, 'max_iter': 425, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:52:12,630]\u001b[0m Trial 33 finished with value: -0.8049640500344726 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 101, 'hidden_layer_sizes_1': 81, 'hidden_layer_sizes_2': 21, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.007543331780037256, 'max_iter': 576, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:52:16,603]\u001b[0m Trial 34 finished with value: -0.7965428937259923 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 61, 'hidden_layer_sizes_1': 61, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.011982170100360151, 'max_iter': 269, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:52:21,791]\u001b[0m Trial 35 finished with value: -0.7979808923470895 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 1, 'hidden_layer_sizes_1': 91, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.0023681701982847117, 'max_iter': 355, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:52:22,700]\u001b[0m Trial 36 finished with value: -0.7952329360780065 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 11, 'hidden_layer_sizes_1': 51, 'hidden_layer_sizes_2': 101, 'activation': 'identity', 'solver': 'lbfgs', 'alpha': 0.016298377477527624, 'max_iter': 420, 'learning_rate': 'adaptive'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:52:34,074]\u001b[0m Trial 37 finished with value: -0.8147641091303063 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 71, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.02658385277664789, 'max_iter': 788, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:52:51,136]\u001b[0m Trial 38 finished with value: -0.7797990741652714 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 91, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.025709029492530566, 'max_iter': 790, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:52:56,109]\u001b[0m Trial 39 finished with value: -0.7980104402639614 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 71, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.02085923881429012, 'max_iter': 914, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:53:07,407]\u001b[0m Trial 40 finished with value: -0.8161528612232838 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 61, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.02672570142621242, 'max_iter': 786, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:53:18,865]\u001b[0m Trial 41 finished with value: -0.7895006402048655 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 61, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.026857381642204435, 'max_iter': 797, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:53:31,614]\u001b[0m Trial 42 finished with value: -0.8007288486161726 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 51, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.031362373678647075, 'max_iter': 883, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:53:43,153]\u001b[0m Trial 43 finished with value: -0.810578154240126 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 81, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.03459169150831698, 'max_iter': 799, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:53:48,500]\u001b[0m Trial 44 finished with value: -0.8008174923667882 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 61, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.024198831891933937, 'max_iter': 747, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:53:58,407]\u001b[0m Trial 45 finished with value: -0.8091401556190287 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 71, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.02950861047007608, 'max_iter': 678, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:54:16,751]\u001b[0m Trial 46 finished with value: -0.80635280212745 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 71, 'hidden_layer_sizes_1': 31, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.018895157079456926, 'max_iter': 926, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:54:22,046]\u001b[0m Trial 47 finished with value: -0.7937949374569093 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 21, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.015317604301331365, 'max_iter': 827, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:54:30,506]\u001b[0m Trial 48 finished with value: -0.7853737811484292 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.022829144129532877, 'max_iter': 551, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:54:45,960]\u001b[0m Trial 49 finished with value: -0.810597852851374 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 11, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.027448329069142668, 'max_iter': 646, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:54:47,151]\u001b[0m Trial 50 finished with value: -0.7980399881808332 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 91, 'hidden_layer_sizes_1': 71, 'activation': 'identity', 'solver': 'lbfgs', 'alpha': 0.019043257923823834, 'max_iter': 751, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:55:01,896]\u001b[0m Trial 51 finished with value: -0.8134344528710727 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 11, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.026535164876493423, 'max_iter': 632, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:55:18,178]\u001b[0m Trial 52 finished with value: -0.8050132965625924 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 61, 'hidden_layer_sizes_1': 11, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.0258758232838795, 'max_iter': 622, 'learning_rate': 'constant'}. Best is trial 12 with value: -0.8162021077514033.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:55:34,643]\u001b[0m Trial 53 finished with value: -0.8162119570570274 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 21, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.03000724142903053, 'max_iter': 707, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:55:49,973]\u001b[0m Trial 54 finished with value: -0.7980202895695855 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 21, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.033982727513776394, 'max_iter': 698, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:56:04,756]\u001b[0m Trial 55 finished with value: -0.8050034472569683 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 31, 'hidden_layer_sizes_1': 1, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.030477826464259616, 'max_iter': 718, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:56:20,316]\u001b[0m Trial 56 finished with value: -0.8022062444597656 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 41, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.028900168364825535, 'max_iter': 766, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:56:32,841]\u001b[0m Trial 57 finished with value: -0.807840047276667 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 11, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.03798479165078933, 'max_iter': 612, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:56:48,772]\u001b[0m Trial 58 finished with value: -0.8078203486654191 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 21, 'hidden_layer_sizes_1': 21, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.02035015669571346, 'max_iter': 679, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:56:54,647]\u001b[0m Trial 59 finished with value: -0.7909878853540825 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'logistic', 'solver': 'adam', 'alpha': 0.022340205076546642, 'max_iter': 833, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:57:11,457]\u001b[0m Trial 60 finished with value: -0.8022062444597655 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 71, 'hidden_layer_sizes_1': 31, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.035820710235491014, 'max_iter': 722, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:57:22,231]\u001b[0m Trial 61 finished with value: -0.8133556584260809 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 41, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.027615963370606133, 'max_iter': 540, 'learning_rate': 'adaptive'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:57:35,517]\u001b[0m Trial 62 finished with value: -0.796601989559736 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 31, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.024844871715167707, 'max_iter': 506, 'learning_rate': 'adaptive'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:57:45,166]\u001b[0m Trial 63 finished with value: -0.7839751797498277 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 81, 'hidden_layer_sizes_1': 41, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.03056313106786508, 'max_iter': 679, 'learning_rate': 'adaptive'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:57:56,346]\u001b[0m Trial 64 finished with value: -0.8063429528218261 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 51, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.023573485155075843, 'max_iter': 560, 'learning_rate': 'adaptive'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:58:10,533]\u001b[0m Trial 65 finished with value: -0.7980104402639613 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 61, 'hidden_layer_sizes_1': 21, 'hidden_layer_sizes_2': 21, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.026853807510137905, 'max_iter': 590, 'learning_rate': 'adaptive'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:58:11,515]\u001b[0m Trial 66 finished with value: -0.7896089825667291 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 11, 'hidden_layer_sizes_1': 11, 'activation': 'identity', 'solver': 'lbfgs', 'alpha': 0.01677729116496103, 'max_iter': 451, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:58:20,925]\u001b[0m Trial 67 finished with value: -0.7979513444302178 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 61, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.028439023088332883, 'max_iter': 645, 'learning_rate': 'adaptive'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:58:36,708]\u001b[0m Trial 68 finished with value: -0.8078301979710429 and parameters: {'hidden_layer_sizes': 4, 'hidden_layer_sizes_0': 71, 'hidden_layer_sizes_1': 1, 'hidden_layer_sizes_2': 101, 'hidden_layer_sizes_3': 1, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.022096291923162575, 'max_iter': 776, 'learning_rate': 'constant'}. Best is trial 53 with value: -0.8162119570570274.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:58:53,890]\u001b[0m Trial 69 finished with value: -0.8203388161134638 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 51, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.03159217287517449, 'max_iter': 878, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:59:10,839]\u001b[0m Trial 70 finished with value: -0.806362651433074 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 41, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.03224312897062541, 'max_iter': 875, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:59:29,862]\u001b[0m Trial 71 finished with value: -0.8105683049345019 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 1, 'hidden_layer_sizes_1': 51, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.031518231532090824, 'max_iter': 991, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 22:59:45,905]\u001b[0m Trial 72 finished with value: -0.8105387570176303 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 21, 'hidden_layer_sizes_1': 31, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.029178774665047293, 'max_iter': 818, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:00:02,610]\u001b[0m Trial 73 finished with value: -0.8021372993203979 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 81, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.025484852932089203, 'max_iter': 855, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:00:20,982]\u001b[0m Trial 74 finished with value: -0.7993302472175712 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 61, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.03295719308789707, 'max_iter': 952, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:00:34,008]\u001b[0m Trial 75 finished with value: -0.8049542007288487 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 61, 'hidden_layer_sizes_1': 21, 'hidden_layer_sizes_2': 71, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.03970857325078104, 'max_iter': 906, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:00:43,191]\u001b[0m Trial 76 finished with value: -0.7769723234511966 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0134309021582855, 'max_iter': 376, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:00:47,890]\u001b[0m Trial 77 finished with value: -0.8106077021569978 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 31, 'hidden_layer_sizes_1': 41, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.024150554650526106, 'max_iter': 317, 'learning_rate': 'constant'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:00:49,914]\u001b[0m Trial 78 finished with value: -0.7909780360484585 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 51, 'activation': 'identity', 'solver': 'adam', 'alpha': 0.026308488709079467, 'max_iter': 697, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:00:59,953]\u001b[0m Trial 79 finished with value: -0.8049443514232246 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 61, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.04920499857345366, 'max_iter': 520, 'learning_rate': 'constant'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:01:10,633]\u001b[0m Trial 80 finished with value: -0.802127450014774 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 41, 'hidden_layer_sizes_1': 61, 'activation': 'logistic', 'solver': 'lbfgs', 'alpha': 0.03033101690332183, 'max_iter': 737, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:01:21,407]\u001b[0m Trial 81 finished with value: -0.8006993006993006 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 41, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.028530341005130744, 'max_iter': 545, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:01:33,053]\u001b[0m Trial 82 finished with value: -0.8119176598049836 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 61, 'hidden_layer_sizes_1': 31, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.027107875753928253, 'max_iter': 592, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:01:42,712]\u001b[0m Trial 83 finished with value: -0.8119373584162316 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 41, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.03487345098839274, 'max_iter': 493, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:01:54,114]\u001b[0m Trial 84 finished with value: -0.8119570570274796 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 71, 'hidden_layer_sizes_1': 51, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.02122398528811112, 'max_iter': 572, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:02:03,104]\u001b[0m Trial 85 finished with value: -0.8049443514232246 and parameters: {'hidden_layer_sizes': 3, 'hidden_layer_sizes_0': 11, 'hidden_layer_sizes_1': 21, 'hidden_layer_sizes_2': 51, 'activation': 'tanh', 'solver': 'lbfgs', 'alpha': 0.023306216031192067, 'max_iter': 451, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:02:17,050]\u001b[0m Trial 86 finished with value: -0.8064414458780658 and parameters: {'hidden_layer_sizes': 2, 'hidden_layer_sizes_0': 51, 'hidden_layer_sizes_1': 81, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.01812614195447079, 'max_iter': 527, 'learning_rate': 'constant'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:02:26,389]\u001b[0m Trial 87 finished with value: -0.8147542598246822 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 41, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.019984551195562045, 'max_iter': 635, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:02:35,653]\u001b[0m Trial 88 finished with value: -0.8077317049148036 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 81, 'activation': 'relu', 'solver': 'lbfgs', 'alpha': 0.019040235950241832, 'max_iter': 629, 'learning_rate': 'constant'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:02:44,519]\u001b[0m Trial 89 finished with value: -0.77416527134837 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 41, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.020376853830134125, 'max_iter': 814, 'learning_rate': 'constant'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:02:55,989]\u001b[0m Trial 90 finished with value: -0.8134049049542007 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.014861143425751875, 'max_iter': 656, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:03:09,037]\u001b[0m Trial 91 finished with value: -0.8134147542598246 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.011652841437874465, 'max_iter': 654, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:03:22,709]\u001b[0m Trial 92 finished with value: -0.8105880035457499 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 21, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.015223156080997757, 'max_iter': 654, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:03:35,965]\u001b[0m Trial 93 finished with value: -0.8134049049542007 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.011674365953088682, 'max_iter': 668, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:03:48,321]\u001b[0m Trial 94 finished with value: -0.8064020486555699 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.010800684619355322, 'max_iter': 669, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:04:01,383]\u001b[0m Trial 95 finished with value: -0.8190091598542303 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.00694846853995943, 'max_iter': 610, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:08:39,748]\u001b[0m Trial 96 finished with value: -0.8119866049443514 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 21, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.007571720196736489, 'max_iter': 612, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:08:53,449]\u001b[0m Trial 97 finished with value: -0.8091992514527725 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 31, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.005053453163259456, 'max_iter': 633, 'learning_rate': 'adaptive'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:09:05,854]\u001b[0m Trial 98 finished with value: -0.8064118979611937 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 41, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.002832985437218981, 'max_iter': 690, 'learning_rate': 'constant'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n",
      "\u001b[32m[I 2022-10-01 23:09:11,019]\u001b[0m Trial 99 finished with value: -0.8176204077612528 and parameters: {'hidden_layer_sizes': 1, 'hidden_layer_sizes_0': 41, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.013442539142792847, 'max_iter': 204, 'learning_rate': 'constant'}. Best is trial 69 with value: -0.8203388161134638.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================================\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "optimization_function = partial(optimization_step, name=\"neural\", train=train, y_train=y_train)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(optimization_function, n_trials=100)\n",
    "    \n",
    "print(\"=========================================================================================================================\")\n",
    "neural = study.best_params\n",
    "print(\"=========================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (41, 51),\n",
       " 'activation': 'tanh',\n",
       " 'solver': 'lbfgs',\n",
       " 'alpha': 0.03159217287517449,\n",
       " 'max_iter': 878,\n",
       " 'learning_rate': 'adaptive'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_neural = neural\n",
    "tmp_neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: -> 0.8892005610098177\n",
      "lgbm: -> 0.908835904628331\n",
      "neural: -> 0.9046283309957924\n",
      "voting: -> 0.9018232819074333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# n_layers = tmp_neural[\"hidden_layer_sizes\"]\n",
    "# # del neural[\"hidden_layer_sizes\"]\n",
    "# size_layer = []\n",
    "\n",
    "# for n in range(n_layers[0]):\n",
    "#     size_layer.append(neural[f\"hidden_layer_sizes_{n}\"])\n",
    "#     del neural[f\"hidden_layer_sizes_{n}\"]\n",
    "\n",
    "# # print(size_layer)\n",
    "# neural[\"hidden_layer_sizes\"] = tuple(size_layer)\n",
    "# print(neural)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(estimators=[(\"rf\", RandomForestClassifier(**rf, random_state=seed, n_jobs=-1)), \\\n",
    "    (\"lgbm\", LGBMClassifier(**lgbm, random_state=seed, n_jobs=-1)), (\"neural\", MLPClassifier(**neural, random_state=seed))])\n",
    "\n",
    "\n",
    "best_classifiers = {\n",
    "    \"rf\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", RandomForestClassifier(**rf, random_state=seed, n_jobs=-1))]),\n",
    "    \"lgbm\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", LGBMClassifier(**lgbm, random_state=seed, n_jobs=-1))]),\n",
    "    \"neural\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", MLPClassifier(**neural, random_state=seed))]),\n",
    "    \"voting\": Pipeline(steps=[(\"preprocessor\", preprocessor), (\"sampling\", SMOTE()), (\"classifier\", voting)])\n",
    "}\n",
    "\n",
    "for name, classifier in best_classifiers.items():\n",
    "    classifier.fit(train, y_train)\n",
    "    \n",
    "    print(f\"{name}: -> {classifier.score(train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf. Accuracy ->  0.81006 | F1 ->  0.74242\n",
      "lgbm. Accuracy ->  0.81564 | F1 ->  0.74809\n",
      "neural. Accuracy ->  0.76536 | F1 ->  0.68657\n",
      "voting. Accuracy ->  0.81006 | F1 ->  0.74242\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, classifier in best_classifiers.items():\n",
    "    y_pred = classifier.predict(test)\n",
    "        # 'confusion': confusion_matrix(y_test, predictions),\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{name}. Accuracy -> {accuracy: .5f} | F1 -> {f1: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>title</th>\n",
       "      <th>Age_present</th>\n",
       "      <th>Embarked_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch   Ticket     Fare Embarked title  \\\n",
       "0       3    male  34.5      0      0   330911   7.8292        Q    Mr   \n",
       "1       3  female  47.0      1      0   363272   7.0000        S   Mrs   \n",
       "2       2    male  62.0      0      0   240276   9.6875        Q    Mr   \n",
       "3       3    male  27.0      0      0   315154   8.6625        S    Mr   \n",
       "4       3  female  22.0      1      1  3101298  12.2875        S   Mrs   \n",
       "\n",
       "   Age_present  Embarked_present  \n",
       "0            1                 1  \n",
       "1            1                 1  \n",
       "2            1                 1  \n",
       "3            1                 1  \n",
       "4            1                 1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_copy = read_csv(\"test.csv\")\n",
    "\n",
    "def courtesy_title(name):\n",
    "    return name.split(',')[-1].split('.')[0].strip()\n",
    "\n",
    "def add_column_present(df, colname):\n",
    "    df[f\"{colname}_present\"] =  np.where(df[colname] != 'NaN', 1, 0)\n",
    "    \n",
    "def group_courtesy_title(title):\n",
    "    keep_titles = ('Mr', 'Miss', 'Mrs', 'Master', 'Dr', 'Rev')\n",
    "    if title not in keep_titles:\n",
    "        title = 'Other'\n",
    "        \n",
    "    return title\n",
    "\n",
    "test_copy[\"title\"] = test_copy['Name'].apply(courtesy_title)\n",
    "passenger_ids = test_copy['PassengerId']\n",
    "test_copy = test_copy.drop([\"Name\", \"Cabin\", \"PassengerId\"], axis=1)\n",
    "test_copy['title'] = test_copy['title'].apply(group_courtesy_title)\n",
    "colnames = [\"Age\", \"Embarked\"]\n",
    "for colname in colnames:\n",
    "    add_column_present(test_copy, colname)\n",
    "    \n",
    "\n",
    "test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy[\"Parch\"] = test_copy['Parch'].replace(9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Is_child'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:822\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    823\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    824\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    825\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    829\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2032.0_x64__qbz5n2kfra8p0\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [64], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m read_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender_submission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m passenger_ids\n\u001b[1;32m----> 4\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbest_classifiers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(results\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      8\u001b[0m results\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/gender_submission_voting.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\pipeline.py:457\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    455\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[0;32m    456\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 457\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[0;32m    458\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\compose\\_column_transformer.py:763\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    759\u001b[0m     \u001b[39m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m    760\u001b[0m     \u001b[39m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m    761\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 763\u001b[0m Xs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(\n\u001b[0;32m    764\u001b[0m     X,\n\u001b[0;32m    765\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    766\u001b[0m     _transform_one,\n\u001b[0;32m    767\u001b[0m     fitted\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    768\u001b[0m     column_as_strings\u001b[39m=\u001b[39;49mfit_dataframe_and_transform_dataframe,\n\u001b[0;32m    769\u001b[0m )\n\u001b[0;32m    770\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    772\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Xs:\n\u001b[0;32m    773\u001b[0m     \u001b[39m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\compose\\_column_transformer.py:621\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    615\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    616\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[0;32m    617\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    619\u001b[0m )\n\u001b[0;32m    620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    622\u001b[0m         delayed(func)(\n\u001b[0;32m    623\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[0;32m    624\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    625\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    626\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[0;32m    627\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    628\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[0;32m    629\u001b[0m         )\n\u001b[0;32m    630\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    631\u001b[0m     )\n\u001b[0;32m    632\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    633\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:833\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    830\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    831\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 833\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    834\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    835\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\compose\\_column_transformer.py:624\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    616\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[0;32m    617\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    619\u001b[0m )\n\u001b[0;32m    620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(\n\u001b[0;32m    622\u001b[0m         delayed(func)(\n\u001b[0;32m    623\u001b[0m             transformer\u001b[39m=\u001b[39mclone(trans) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted \u001b[39melse\u001b[39;00m trans,\n\u001b[1;32m--> 624\u001b[0m             X\u001b[39m=\u001b[39m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    625\u001b[0m             y\u001b[39m=\u001b[39my,\n\u001b[0;32m    626\u001b[0m             weight\u001b[39m=\u001b[39mweight,\n\u001b[0;32m    627\u001b[0m             message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumnTransformer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    628\u001b[0m             message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(name, idx, \u001b[39mlen\u001b[39m(transformers)),\n\u001b[0;32m    629\u001b[0m         )\n\u001b[0;32m    630\u001b[0m         \u001b[39mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(transformers, \u001b[39m1\u001b[39m)\n\u001b[0;32m    631\u001b[0m     )\n\u001b[0;32m    632\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    633\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\__init__.py:359\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    354\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSpecifying the columns using strings is only supported for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpandas DataFrames\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m     )\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 359\u001b[0m     \u001b[39mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    360\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\__init__.py:205\u001b[0m, in \u001b[0;36m_pandas_indexing\u001b[1;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[39m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     indexer \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc \u001b[39mif\u001b[39;00m key_dtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mint\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39mloc\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m indexer[:, key] \u001b[39mif\u001b[39;00m axis \u001b[39melse\u001b[39;00m indexer[key]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1149\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:827\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    825\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    828\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1194\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1192\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1196\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1327\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1328\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1330\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1332\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5793\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5796\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5798\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5800\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:5859\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5858\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5859\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Is_child'] not in index\""
     ]
    }
   ],
   "source": [
    "results = read_csv(\"gender_submission.csv\")\n",
    "\n",
    "results['PassengerId'] = passenger_ids\n",
    "results[\"Survived\"] = best_classifiers[\"voting\"].predict(test_copy)\n",
    "\n",
    "print(results.head())\n",
    "\n",
    "results.to_csv(os.path.join(os.getcwd(), \"dataset/gender_submission_voting.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1f2b33e866b0bf2409397e5f58ba9cdf170d3b7f64c8f359c79998e2f88ad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
